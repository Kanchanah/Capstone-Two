{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Two - Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used was the 2017 National Household Travel Survey. This notebook will focus on the cleaning the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import tabula\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')\n",
    "cw = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Avinash/Documents/Kanchanah/Springboard/Data_Science_Track'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The National Household Travel Survey has 4 datasets. \n",
    "\n",
    "1. The Person dataset \n",
    "2. The Household dataset\n",
    "3. The Vehicle dataset\n",
    "4. The Travel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import person data\n",
    "data_person=pd.read_sas(os.path.join(cw ,'Capstone_Two_Other_Material/Data/sas/perpub.sas7bdat'), format = 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at first few rows\n",
    "data_person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks at dimension\n",
    "data_person.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_person.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select string variables\n",
    "data_person_obj = data_person.select_dtypes(['object'])\n",
    "print (data_person_obj.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove trailing or leading spaces\n",
    "data_person[data_person_obj.columns] = data_person_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_person.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_person.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import household data\n",
    "data_hh=pd.read_sas(os.path.join(cw,'Capstone_Two_Other_Material/Data/sas/hhpub.sas7bdat'), format = 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at first few rows\n",
    "data_hh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_hh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_hh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select string variables\n",
    "data_hh_obj = data_hh.select_dtypes(['object'])\n",
    "print (data_hh_obj.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove trailing or leading spaces\n",
    "data_hh[data_hh_obj.columns] = data_hh_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_hh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_hh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import trip data\n",
    "data_trip=pd.read_sas(os.path.join(cw,'Capstone_Two_Other_Material/Data/sas/trippub.sas7bdat'), format = 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at first few rows\n",
    "data_trip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_trip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_trip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select string variables\n",
    "data_trip_obj = data_trip.select_dtypes(['object'])\n",
    "print (data_trip_obj.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove trailing or leading spaces\n",
    "data_trip[data_trip_obj.columns] = data_trip_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_trip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dataset info\n",
    "data_trip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import vehicle data\n",
    "data_veh=pd.read_sas(os.path.join(cw,'Capstone_Two_Other_Material/Data/sas/vehpub.sas7bdat'), format = 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at first few rows\n",
    "data_veh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_veh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_veh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select string variables\n",
    "data_veh_obj = data_veh.select_dtypes(['object'])\n",
    "print (data_veh_obj.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove trailing or leading spaces\n",
    "data_veh[data_veh_obj.columns] = data_veh_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_veh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_veh.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the User Guide documentation provided, many of the variables are repeated across multiple table file levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at similar variables between datasets we want to merge and save them in variables\n",
    "data_hh_columns = set(data_hh.columns)\n",
    "data_veh_columns = set(data_veh.columns)\n",
    "data_person_columns = set(data_person.columns)\n",
    "data_trip_columns = set(data_trip.columns)\n",
    "\n",
    "data_hh_veh_columns = list(data_hh_columns.intersection(data_veh_columns))\n",
    "data_hh_veh_columns_u = list(data_hh_columns.union(data_veh_columns))\n",
    "\n",
    "data_hh_veh_person_columns = list(set(data_hh_veh_columns_u).intersection(data_person_columns))\n",
    "data_hh_veh_person_columns_u = list(set(data_hh_veh_columns_u).union(data_person_columns))\n",
    "\n",
    "data_hh_veh_person_trip_columns = list(set(data_hh_veh_person_columns_u).intersection(data_trip_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge person and vehicle data\n",
    "data_hh_veh = pd.merge(data_hh,data_veh,on=data_hh_veh_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at first 5 rows\n",
    "data_hh_veh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension of data\n",
    "data_hh_veh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge household and vehicle data to person data\n",
    "data_hh_veh_person = pd.merge(data_hh_veh,data_person,on=data_hh_veh_person_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at first 5 rows\n",
    "data_hh_veh_person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension of data\n",
    "data_hh_veh_person.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge person, household data, vehicle data to trip data\n",
    "data_hh_veh_person_trip = pd.merge(data_hh_veh_person,data_trip,on=data_hh_veh_person_trip_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review first few rows\n",
    "data_hh_veh_person_trip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review dimension\n",
    "data_hh_veh_person_trip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the data\n",
    "data = data_hh_veh_person_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nLook at data info\n",
    "data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#reorder variables\n",
    "first_cols = ['PERSONID','VEHID']\n",
    "last_cols = [col for col in data.columns if col not in first_cols]\n",
    "len(last_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder variables\n",
    "data1 = data[first_cols+last_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get first few rows\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension of data\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates and NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Any duplicate rows?\n",
    "data1 = data1.drop_duplicates()\n",
    "#Dimension\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for NAs\n",
    "data1.isna().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no NAs in the dataset. The documentation for the dataset mentioned that there shouldn't be any as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few values that should be reviewed further.\n",
    "\n",
    "1. -7 : Refused\n",
    "2. -8 : Don't Know\n",
    "3. -9 : Not Ascertained\n",
    "4. -1 : Appropriate Skip\n",
    "\n",
    "Let's check if any variable consists of all of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_check_val = data1.isin([-1.0,-7.0,-8.0,-9.0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_check_val[data1_check_val==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the variables consist of only these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Codebook and Apply Values Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import excel version of codebook\n",
    "codebookname=pd.ExcelFile(os.path.join(cw,'Documentation/codebook_v1.2.xlsx'))\n",
    "print(codebookname.sheet_names)\n",
    "codebook=pd.read_excel(os.path.join(cw,'Documentation/codebook_v1.2.xlsx'))\n",
    "\n",
    "for items in codebookname.sheet_names[1:]:\n",
    "    codebook_new=pd.read_excel(os.path.join(cw,'Documentation/codebook_v1.2.xlsx'),sheet_name=items)\n",
    "    codebook=pd.concat([codebook,codebook_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at first few rows\n",
    "codebook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension of data\n",
    "codebook.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward fill\n",
    "codebook = codebook.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get first few rows\n",
    "codebook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all rows for character variables\n",
    "codebook_c = codebook[codebook.Type=='C'].reset_index(drop=True)\n",
    "codebook_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape codebook\n",
    "codebook_reshape_c = codebook_c.groupby(['Name','Type'])['Code / Range'].agg('='.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dimension\n",
    "codebook_reshape_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get first few rows\n",
    "codebook_reshape_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get last few rows\n",
    "codebook_reshape_c.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split with equal\n",
    "codebook_reshape_c['New'] = codebook_reshape_c['Code / Range'].str.split('=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first few rows\n",
    "codebook_reshape_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dimension of data\n",
    "codebook_reshape_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new column\n",
    "codebook_reshape_c['New_m'] = codebook_reshape_c['New'].apply(lambda x: dict(zip(x[::2], x[1::2])))\n",
    "codebook_reshape_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dict variables to loop\n",
    "val_label = dict(zip(codebook_reshape_c.Name,codebook_reshape_c.New_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add labels and make variables string\n",
    "for key, val in val_label.items():\n",
    "    data1[key].replace(val,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review first few rows\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dimension\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select string variables\n",
    "data1_char = data1.select_dtypes(['object'])\n",
    "print (data1_char.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a review of these variables\n",
    "#Remove trailing or leading spaces\n",
    "data1[data1_char.columns] = data1_char.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dimension of data\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at first few rows\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get information about dataset\n",
    "data1.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Format for Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the variables represent counts or int variables and have been given as float. Convert them to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get these variables\n",
    "data_1_int =data1[[\"BIKE4EX\",\"BIKESHARE\",\"CARRODE\",\"CARSHARE\",\"CNTTDHH\",\"CNTTDTR\",\"DELIVER\",\"DRVRCNT\",\n",
    "                   \"HHSIZE\",\"HHVEHCNT\",\"LPACT\",\"MCUSED\",\"NBIKETRP\",\"NUMADLT\",\t\"NUMONTRP\",\t\"NUMTRANS\",\n",
    "                   \"NWALKTRP\",\"PTUSED\",\"RESP_CNT\",\"RIDESHARE\",\"TRPACCMP\",\"TRPHHACC\",\"VEHYEAR\",\"VPACT\",\"WALK4EX\",\n",
    "                   \"WKFMHMXX\",\"WRKCOUNT\",\"YOUNGCHILD\",\"YRTOUS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert type\n",
    "data1[data_1_int.columns]=data_1_int.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check first few rows\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dimension\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset for all numeric variables\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "data1_num = data1.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we are working on checking the outliers, let's make some of the values NA so that they don't \n",
    "#lead to misleading results\n",
    "\n",
    "data2_num = data1_num.replace(dict.fromkeys([-1.0,-7.0,-8.0,-9.0], np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dimension of data\n",
    "data2_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the respective quantiles for the variables and caluclate IQR\n",
    "Q1 = data2_num.quantile(0.25)\n",
    "Q3 = data2_num.quantile(0.75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for outliers\n",
    "data2_num_check = ((data2_num < (Q1 - 1.5 * IQR)) | (data2_num > (Q3 + 1.5 * IQR))).sum().to_frame().\n",
    "reset_index().rename(columns={0:'sum','index':'Name'})\n",
    "data2_num_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a data frame with the outliers\n",
    "num_outlier_cases = data2_num_check[data2_num_check['sum'] >0].reset_index(drop=True)\n",
    "num_outlier_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these variables can be removed. All weight variables WTHHFIN, WTPERFIN, WTTRDFIN can be removed from the list. Let's look at a few more variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The variables HHSIZE shows the number of people in a household. Let's check for the min and max of that variable.\n",
    "data2_num['HHSIZE'].min(), data2_num['HHSIZE'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the number of people in a household ranges from 1 to 13. If the counts for the variables DRVRCNT, NUMADLT, YOUNGCHILD, WRKCOUNT, RESP_CNT are within this range or lesser we should be good and can drop these variables and focus on the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_num[[\"DRVRCNT\", \"NUMADLT\",\"YOUNGCHILD\",\"WRKCOUNT\",\"RESP_CNT\"]].max(axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_num[[\"DRVRCNT\", \"NUMADLT\",\"YOUNGCHILD\",\"WRKCOUNT\",\"RESP_CNT\"]].min(axis=1).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables will be dropped from the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outlier_cases1 = num_outlier_cases[~num_outlier_cases.Name.isin([\"HHSIZE\",\"DRVRCNT\", \"NUMADLT\",\n",
    "                                                                     \"YOUNGCHILD\",\"WRKCOUNT\",\"RESP_CNT\",\n",
    "                                                                     \"WTHHFIN\", \"WTPERFIN\", \n",
    "                                                                     \"WTTRDFIN\"])].reset_index(drop=True)\n",
    "num_outlier_cases1.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go through one by one to see if the values are possible. Look at the first 15.\n",
    "\n",
    "selection = list(num_outlier_cases1.Name)[0:15]\n",
    "fig, axes = plt.subplots(figsize=(12,10),nrows=3, ncols=5)\n",
    "for i, col in enumerate(selection):\n",
    "    ax = sns.boxplot(y=data2_num[col], ax=axes.flatten()[i])\n",
    "\n",
    "fig.subplots_adjust(wspace=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the results one by one and state if the values are possible or not.\n",
    "\n",
    "1. HHVEHCNT - Count of household vehicles\n",
    "   - It is possible for the household vehicles to have 12 vehicles, especially if the number of household members are huge.\n",
    "2. CNTTDHH - Count of household trips on travel day\n",
    "   - This seems pretty huge but its not impossible.\n",
    "3. VEHYEAR - Vehicle Year\n",
    "   - 1970s is a possible year for vehicles.\n",
    "4. VEHAGE - Age of vehicle, based on model year\n",
    "   - This is also possible based on vehicle year.\n",
    "5. OD_READ - Odometer Reading\n",
    "   - A value as high as a million is possible.\n",
    "6. ANNMILES - Self-reported annualized mile estimates\n",
    "   - These values are possible\n",
    "7. BESTMILE - Best estimate of annual miles\n",
    "   - These values are possible\n",
    "8. GSYRGAL - Annual fuel consumption in US gallons\n",
    "   - These values are possible\n",
    "9. GSTOTCST - Annual fuel expenditures in US dollars\n",
    "   - These values are possible\n",
    "10. FEGEMPG - Fuel Economy.gov EIA-Derived 55/45 fuel economy\n",
    "   - These values are possible\n",
    "11. FEGEMPGA - Fuel Economy.gov 55/45 alternative fuel economy\n",
    "   - These values are possible\n",
    "12. GSCOST - Annualized fuel cost in US cents per equivalent gallon\n",
    "   - These values are possible\n",
    "   - Having more than 1 young child is definitely possible since some households have 12 people.\n",
    "13. NWALKTRP - Count of Walk Trips\n",
    "   - **These values are possible but they are relatively high**\n",
    "14. WALK4EX - Count of Walk Trips for Exercise\n",
    "   - **These values are possible but they are relatively high**\n",
    "15. NBIKETRP - Count of Bike Trips\n",
    "   - **These values are possible but they are relatively high**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go through one by one to see if the values are possible. Look at the next 15.\n",
    "\n",
    "selection = list(num_outlier_cases1.Name)[15:30]\n",
    "fig, axes = plt.subplots(figsize=(12,10),nrows=3, ncols=5)\n",
    "for i, col in enumerate(selection):\n",
    "    ax = sns.boxplot(y=data2_num[col], ax=axes.flatten()[i])\n",
    "\n",
    "fig.subplots_adjust(wspace=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. BIKE4EX - Count of Bike Trips for Exercise\n",
    "   - These values are possible\n",
    "17. BIKESHARE - Count of Bike Share Program Usage\n",
    "   - These values are possible\n",
    "18. PTUSED - Count of Public Transit Usage\n",
    "   - These values are possible\n",
    "19. MCUSED - Count of Motorcycle or Moped Trips\n",
    "   - These values are possible\n",
    "20. CARSHARE - Count of Car Share Program Usage\n",
    "   - These values are possible since it is over 30 day period\n",
    "21. RIDESHARE - Count of Rideshare App Usage\n",
    "   - These values are possible\n",
    "22. CARRODE - Count of People in Vehicle to Work\n",
    "   - These values are possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was going to check all the variables that are supposedly outliers. However, I did notice that the codebook had some of the extreme values. If I check with the codebook and I see that the extreme values exist in the codebook, could I drop the variables from review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: <br>\n",
    "U.S. Department of Transportation, Federal Highway Administration, 2017 National Household Travel Survey. URL: http://nhts.ornl.gov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
